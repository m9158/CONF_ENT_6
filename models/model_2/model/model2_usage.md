# ğŸ“˜ Model 2 ì‚¬ìš© ê°€ì´ë“œ (Part 3 ì‹œë®¬ë ˆì´ì…˜ìš©)

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” **Model 2 (ë™ì  ìˆ˜ìµ ê³¡ì„  ì˜ˆì¸¡ ì—”ì§„)**ì˜ ì‚°ì¶œë¬¼ì„ **Part 3 (ì‚°ì—… ìƒíƒœê³„ ì‹œë®¬ë ˆì´ì…˜)**ì—ì„œ ì–´ë–»ê²Œ í™œìš©í•˜ëŠ”ì§€ ì„¤ëª…í•©ë‹ˆë‹¤.

---

## ğŸ¯ Model 2ì˜ ì—­í• 

Model 2ëŠ” Part 3 ì‹œë®¬ë ˆì´ì…˜ì˜ **í•µì‹¬ ì˜ˆì¸¡ ì—”ì§„**ìœ¼ë¡œ, ë‹¤ìŒì„ ì œê³µí•©ë‹ˆë‹¤:

1. **Rb(t) ì˜ˆì¸¡**: OTT ê°œì…ì´ ì—†ì„ ë•Œì˜ ìì—°ìŠ¤ëŸ¬ìš´ ê·¹ì¥ ìˆ˜ìµ ê³¡ì„ 
2. **Ra(t) ì‹œë®¬ë ˆì´ì…˜**: íŠ¹ì • í™€ë“œë°±(t) ì ìš© ì‹œ OTT ì¶œì‹œ í›„ ê·¹ì¥ ìˆ˜ìµ ê³¡ì„ 
3. **ì˜í™”ë³„ íŠ¹ì„±**: TFS, ONS, ì ì‹ ê³„ìˆ˜(C), Gamma(Î³)

---

## ğŸ“¦ Model 2 ì‚°ì¶œë¬¼ (Outputs)

### 1. í•™ìŠµëœ LSTM ëª¨ë¸ (`model_2A_Rb_LSTM.h5`)

- **ì—­í• **: Rb(t) ì˜ˆì¸¡ (ìì—° ìˆ˜ìµ ê³¡ì„ )
- **ì…ë ¥**: ê³¼ê±° 7ì¼ê°„ì˜ 6ê°œ í”¼ì²˜ ì‹œí€€ìŠ¤
- **ì¶œë ¥**: 8ì¼ì§¸ ì¼ì¼ ê·¹ì¥ ë§¤ì¶œì•¡
- **ìš©ë„**: Rolling Predictionìœ¼ë¡œ ì „ì²´ ìƒì•  ì£¼ê¸°(180ì¼) ìˆ˜ìµ ê³¡ì„  ìƒì„±

```python
# ë¡œë“œ ë°©ë²•
from tensorflow.keras.models import load_model
model_Rb = load_model('model_2/model_2A_Rb_LSTM.h5')
```

---

### 2. ìŠ¤ì¼€ì¼ëŸ¬ (`scaler_X.pkl`, `scaler_y.pkl`)

- **scaler_X**: ì…ë ¥ í”¼ì²˜ ì •ê·œí™” (6ê°œ í”¼ì²˜)
- **scaler_y**: íƒ€ê²Ÿ ë³€ìˆ˜ ì •ê·œí™” (daily_sales_amt)
- **ìš©ë„**: ì˜ˆì¸¡ ì „/í›„ ìŠ¤ì¼€ì¼ ë³€í™˜

```python
# ë¡œë“œ ë°©ë²•
import pickle
scaler_X = pickle.load(open('model_2/scaler_X.pkl', 'rb'))
scaler_y = pickle.load(open('model_2/scaler_y.pkl', 'rb'))
```

---

### 3. ì˜í™” ë©”íƒ€ë°ì´í„° (`movie_meta_with_cannib.csv`)

- **í¬í•¨ ì»¬ëŸ¼**:
  - `movie_cd`: ì˜í™” ì½”ë“œ
  - `movie_nm`: ì˜í™”ëª…
  - `genre`, `genre_en`: ì¥ë¥´ (í•œê¸€/ì˜ë¬¸)
  - `openDt`: ê°œë´‰ì¼
  - `open_year`: ê°œë´‰ ì—°ë„
  - `TFS`: Theatrical-First Score (ê·¹ì¥ ì í•©ë„, 0~10)
  - `ONS`: OTT-Native Score (OTT ì í•©ë„, 0~10)
  - `gamma`: ì†Œë¹„ì ì„ í˜¸ë„ (Log ê°’, ì—°ë„ë³„)
  - `cannibalization_coef`: ì ì‹ ê³„ìˆ˜ (C, 0~1)

```python
# ë¡œë“œ ë°©ë²•
import pandas as pd
movie_meta = pd.read_csv('model_2/movie_meta_with_cannib.csv', encoding='utf-8')
```

---

### 4. í†µí•© íŒŒì´í”„ë¼ì¸ í•¨ìˆ˜

#### â‘  `predict_revenue_curves(movie_id, holdback_days, horizon)`

- **ëª©ì **: íŠ¹ì • ì˜í™”ì˜ Rb/Ra ê³¡ì„  ì˜ˆì¸¡
- **íŒŒë¼ë¯¸í„°**:
  - `movie_id` (str): ì˜í™” ì½”ë“œ
  - `holdback_days` (int): í™€ë“œë°± ê¸°ê°„ (ê¸°ë³¸ê°’: 30ì¼)
  - `horizon` (int): ì˜ˆì¸¡ ê¸°ê°„ (ê¸°ë³¸ê°’: 180ì¼)
- **ë°˜í™˜ê°’**:
  - `days`: ë‚ ì§œ ë°°ì—´ (1~180)
  - `Rb_curve`: Rb(t) ì˜ˆì¸¡ê°’ ë°°ì—´
  - `Ra_curve`: Ra(t) ì‹œë®¬ë ˆì´ì…˜ ê°’ ë°°ì—´
  - `movie_info`: ì˜í™” ë©”íƒ€ë°ì´í„° (dict)

#### â‘¡ `plot_revenue_curves(movie_id, holdback_days, horizon)`

- **ëª©ì **: Rb/Ra ê³¡ì„  ì‹œê°í™”
- **ì¶œë ¥**: 
  - Rb vs Ra ë¹„êµ ê·¸ë˜í”„
  - ì ì‹ ì˜ì—­ í‘œì‹œ
  - ì´ìˆ˜ìµ í†µê³„

---

## ğŸ”— Part 3 ì‹œë®¬ë ˆì´ì…˜ í™œìš© ë°©ë²•

### ì‹œë‚˜ë¦¬ì˜¤ 1: ê°œë³„ ì˜í™” ìµœì  í™€ë“œë°± ì°¾ê¸° (Part 3-1)

**ëª©í‘œ**: íŠ¹ì • ì˜í™”ì˜ ë°°ê¸‰ì‚¬ ìˆ˜ìµ(Î M)ì„ ê·¹ëŒ€í™”í•˜ëŠ” ìµœì  í™€ë“œë°±(t*) ì°¾ê¸°

```python
import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
import pickle

# ===========================
# 1. Model 2 ì‚°ì¶œë¬¼ ë¡œë“œ
# ===========================
model_Rb = load_model('model_2/model_2A_Rb_LSTM.h5')
scaler_X = pickle.load(open('model_2/scaler_X.pkl', 'rb'))
scaler_y = pickle.load(open('model_2/scaler_y.pkl', 'rb'))
movie_meta = pd.read_csv('model_2/movie_meta_with_cannib.csv', encoding='utf-8')

# ===========================
# 2. íƒ€ê²Ÿ ì˜í™” ì„ íƒ
# ===========================
target_movie_id = '20124079'  # ì˜ˆ: ë²”ì£„ë„ì‹œ2
movie_info = movie_meta[movie_meta['movie_cd'] == target_movie_id].iloc[0]

print(f"ì˜í™”: {movie_info['movie_nm']}")
print(f"ì¥ë¥´: {movie_info['genre_en']}")
print(f"TFS: {movie_info['TFS']:.1f} | ONS: {movie_info['ONS']:.1f}")
print(f"ì ì‹ê³„ìˆ˜(C): {movie_info['cannibalization_coef']:.3f}")

# ===========================
# 3. í™€ë“œë°± ì‹œë‚˜ë¦¬ì˜¤ ì‹œë®¬ë ˆì´ì…˜
# ===========================
holdback_scenarios = range(0, 181, 10)  # 0ì¼~180ì¼, 10ì¼ ê°„ê²©
results = []

for t_sim in holdback_scenarios:
    # Rb/Ra ì˜ˆì¸¡
    days, Rb_curve, Ra_curve, _ = predict_revenue_curves(
        target_movie_id, 
        holdback_days=t_sim, 
        horizon=180
    )
    
    # ê·¹ì¥ ìˆ˜ìµ ê³„ì‚°
    theater_revenue_before = np.sum(Rb_curve[:t_sim])  # í™€ë“œë°± ì´ì „
    theater_revenue_after = np.sum(Ra_curve[t_sim:])   # í™€ë“œë°± ì´í›„
    total_theater_revenue = theater_revenue_before + theater_revenue_after
    
    # OTT ê¶Œë¦¬ë£Œ ê³„ì‚° (Model 3 ì—°ë™)
    tau = calculate_digital_fee(
        holdback=t_sim,
        tfs=movie_info['TFS'],
        ons=movie_info['ONS'],
        production_cost=movie_info.get('production_cost', 5e9)  # ê¸°ë³¸ 50ì–µ
    )
    
    # ì´ìˆ˜ìµ (ë°°ê¸‰ì‚¬)
    total_profit = total_theater_revenue + tau
    
    results.append({
        'holdback': t_sim,
        'theater_revenue': total_theater_revenue,
        'ott_fee': tau,
        'total_profit': total_profit
    })

# ===========================
# 4. ìµœì  í™€ë“œë°± ë„ì¶œ
# ===========================
results_df = pd.DataFrame(results)
optimal_row = results_df.loc[results_df['total_profit'].idxmax()]

print(f"\nâœ… ìµœì  í™€ë“œë°±: {optimal_row['holdback']:.0f}ì¼")
print(f"   - ê·¹ì¥ ìˆ˜ìµ: {optimal_row['theater_revenue']/1e8:.1f}ì–µ")
print(f"   - OTT ê¶Œë¦¬ë£Œ: {optimal_row['ott_fee']/1e8:.1f}ì–µ")
print(f"   - ì´ìˆ˜ìµ: {optimal_row['total_profit']/1e8:.1f}ì–µ")
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì˜í™” ìœ í˜•ë³„ ìµœì  í™€ë“œë°± ë¶„ì„ (Part 3-2)

**ëª©í‘œ**: TFS/ONSì— ë”°ë¥¸ ì˜í™” ìœ í˜•ë³„ í™€ë“œë°± ì „ëµ ë¹„êµ

```python
# ===========================
# 1. ì˜í™” ìœ í˜• ë¶„ë¥˜
# ===========================
# High TFS (ê·¹ì¥ ì´ë²¤íŠ¸í˜•)
high_tfs_movies = movie_meta[movie_meta['TFS'] >= 7.0]

# High ONS (OTT ì¹œí™”í˜•)
high_ons_movies = movie_meta[movie_meta['ONS'] >= 7.0]

# ===========================
# 2. ìœ í˜•ë³„ ìµœì  í™€ë“œë°± ê³„ì‚°
# ===========================
def find_optimal_holdback(movie_list, holdback_range=range(0, 181, 10)):
    """ì˜í™” ë¦¬ìŠ¤íŠ¸ì˜ í‰ê·  ìµœì  í™€ë“œë°± ê³„ì‚°"""
    optimal_holdbacks = []
    
    for idx, movie in movie_list.iterrows():
        results = []
        for t_sim in holdback_range:
            days, Rb, Ra, _ = predict_revenue_curves(
                movie['movie_cd'], 
                holdback_days=t_sim, 
                horizon=180
            )
            theater_rev = np.sum(Rb[:t_sim]) + np.sum(Ra[t_sim:])
            tau = calculate_digital_fee(t_sim, movie['TFS'], movie['ONS'])
            total = theater_rev + tau
            results.append((t_sim, total))
        
        optimal_t = max(results, key=lambda x: x[1])[0]
        optimal_holdbacks.append(optimal_t)
    
    return np.mean(optimal_holdbacks), np.std(optimal_holdbacks)

# High TFS ì˜í™”ë“¤ì˜ ìµœì  í™€ë“œë°±
tfs_mean, tfs_std = find_optimal_holdback(high_tfs_movies.head(10))
print(f"High TFS ì˜í™” ìµœì  í™€ë“œë°±: {tfs_mean:.0f}ì¼ (Â±{tfs_std:.0f})")

# High ONS ì˜í™”ë“¤ì˜ ìµœì  í™€ë“œë°±
ons_mean, ons_std = find_optimal_holdback(high_ons_movies.head(10))
print(f"High ONS ì˜í™” ìµœì  í™€ë“œë°±: {ons_mean:.0f}ì¼ (Â±{ons_std:.0f})")
```

**ì˜ˆìƒ ê²°ê³¼**:
- High TFS (ë¸”ë¡ë²„ìŠ¤í„°): 90~120ì¼ (ê·¹ì¥ ìˆ˜ìµ ê·¹ëŒ€í™”)
- High ONS (ë“œë¼ë§ˆ/ë¡œë§¨ìŠ¤): 30~45ì¼ (ë¹ ë¥¸ OTT ì „í™˜)

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ ë¹„êµ (Part 3-3)

**ëª©í‘œ**: ì‚°ì—… ì „ì²´ íš¨ìš©(W_Industry) ë¹„êµ

```python
# ===========================
# ì •ì±… ì‹œë‚˜ë¦¬ì˜¤ ì •ì˜
# ===========================
policies = {
    'Laissez-faire': {
        'description': 'ì™„ì „ ììœ¨ (ì˜í™”ë³„ ìµœì  í™€ë“œë°±)',
        'apply_fn': lambda movie: find_movie_optimal_holdback(movie)
    },
    'Uniform_90': {
        'description': 'ì¼ê´„ ê·œì œ (ëª¨ë“  ì˜í™” 90ì¼)',
        'apply_fn': lambda movie: 90
    },
    'Dynamic': {
        'description': 'ë™ì  ì°¨ë“± (TFS/ONS ê¸°ë°˜)',
        'apply_fn': lambda movie: 90 if movie['TFS'] >= 7 else 30
    }
}

# ===========================
# ì´í•´ê´€ê³„ìë³„ íš¨ìš© ê³„ì‚°
# ===========================
def calculate_stakeholder_utilities(policy_name, holdback_fn):
    """ì •ì±…ì— ë”°ë¥¸ ì´í•´ê´€ê³„ìë³„ íš¨ìš© ê³„ì‚°"""
    
    # ë°°ê¸‰ì‚¬ íš¨ìš© (U_MD)
    U_MD = 0
    for idx, movie in movie_meta.iterrows():
        t = holdback_fn(movie)
        days, Rb, Ra, _ = predict_revenue_curves(movie['movie_cd'], t, 180)
        theater_rev = np.sum(Rb[:t]) + np.sum(Ra[t:])
        tau = calculate_digital_fee(t, movie['TFS'], movie['ONS'])
        U_MD += (theater_rev + tau)
    
    # ë…ë¦½ ì œì‘ì‚¬ íš¨ìš© (U_Indie)
    indie_movies = movie_meta[movie_meta['TFS'] < 5.0]  # Low TFS
    U_Indie = 0
    discount_rate = 0.2  # ì—° 20%
    for idx, movie in indie_movies.iterrows():
        t = holdback_fn(movie)
        # í˜„ê¸ˆ íë¦„ í• ì¸ìœ¨ ì ìš©
        tau = calculate_digital_fee(t, movie['TFS'], movie['ONS'])
        discounted_tau = tau / (1 + discount_rate * t/365)
        U_Indie += discounted_tau
    
    # êµ­ë‚´ OTT íš¨ìš© (U_Local_OTT)
    ott_friendly = movie_meta[movie_meta['ONS'] >= 7.0]  # High ONS
    U_OTT = 0
    for idx, movie in ott_friendly.iterrows():
        t = holdback_fn(movie)
        # ì‹ ì„ ë„ í•¨ìˆ˜: í™€ë“œë°±ì´ ê¸¸ìˆ˜ë¡ ê°€ì¹˜ ê°ì†Œ
        freshness = np.exp(-0.01 * t)  # Exponential decay
        content_value = movie['ONS'] * freshness
        U_OTT += content_value
    
    # ì†Œë¹„ì íš¨ìš© (U_Consumer)
    U_Consumer = 0
    for idx, movie in movie_meta.iterrows():
        t = holdback_fn(movie)
        # í™€ë“œë°±ì´ ê¸¸ìˆ˜ë¡ ë¶ˆë²• ë³µì œ ìœ„í—˜ ì¦ê°€
        piracy_penalty = 0.001 * t * movie['gamma']  # Gamma ë°˜ì˜
        U_Consumer -= piracy_penalty
    
    return {
        'policy': policy_name,
        'U_MD': U_MD,
        'U_Indie': U_Indie,
        'U_OTT': U_OTT,
        'U_Consumer': U_Consumer,
        'W_Industry': U_MD + U_Indie + U_OTT + U_Consumer
    }

# ===========================
# ì •ì±…ë³„ ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰
# ===========================
policy_results = []
for policy_name, policy_config in policies.items():
    print(f"\nğŸ”„ ì‹œë®¬ë ˆì´ì…˜: {policy_config['description']}")
    result = calculate_stakeholder_utilities(policy_name, policy_config['apply_fn'])
    policy_results.append(result)
    print(f"   - ì‚°ì—… ì „ì²´ íš¨ìš©(W): {result['W_Industry']/1e12:.2f}ì¡°")

# ===========================
# ê²°ê³¼ ë¹„êµ
# ===========================
results_df = pd.DataFrame(policy_results)
best_policy = results_df.loc[results_df['W_Industry'].idxmax()]

print(f"\nâœ… ìµœì  ì •ì±…: {best_policy['policy']}")
print(f"   - ë°°ê¸‰ì‚¬ íš¨ìš©: {best_policy['U_MD']/1e12:.2f}ì¡°")
print(f"   - ë…ë¦½ ì œì‘ì‚¬: {best_policy['U_Indie']/1e12:.2f}ì¡°")
print(f"   - êµ­ë‚´ OTT: {best_policy['U_OTT']:.2f}")
print(f"   - ì†Œë¹„ì: {best_policy['U_Consumer']:.2f}")
print(f"   - ì „ì²´ íš¨ìš©: {best_policy['W_Industry']/1e12:.2f}ì¡°")
```

---

## ğŸ“Š ë°ì´í„° íë¦„ (Model 2 â†’ Part 3)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MODEL 2 ì‚°ì¶œë¬¼                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1. model_2A_Rb_LSTM.h5 (LSTM ëª¨ë¸)                      â”‚
â”‚ 2. scaler_X.pkl, scaler_y.pkl (ìŠ¤ì¼€ì¼ëŸ¬)                 â”‚
â”‚ 3. movie_meta_with_cannib.csv (ì˜í™” ë©”íƒ€ + ì ì‹ê³„ìˆ˜)    â”‚
â”‚ 4. predict_revenue_curves() í•¨ìˆ˜                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PART 3-1: ê°œë³„ ìµœì í™”                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Input: movie_id, holdback (0~180ì¼)                     â”‚
â”‚                                                          â”‚
â”‚ Process:                                                 â”‚
â”‚  1. predict_revenue_curves(movie_id, t_sim)             â”‚
â”‚     â†’ Rb(t), Ra(t) ì˜ˆì¸¡                                  â”‚
â”‚                                                          â”‚
â”‚  2. ê·¹ì¥ ìˆ˜ìµ ê³„ì‚°:                                       â”‚
â”‚     âˆ«[0â†’t] Rb(z)dz + âˆ«[tâ†’T] Ra(z)dz                     â”‚
â”‚                                                          â”‚
â”‚  3. OTT ê¶Œë¦¬ë£Œ ê³„ì‚° (Model 3):                           â”‚
â”‚     Ï„(t, TFS, ONS)                                      â”‚
â”‚                                                          â”‚
â”‚  4. ì´ìˆ˜ìµ ê³„ì‚°:                                          â”‚
â”‚     Î M = ê·¹ì¥ ìˆ˜ìµ + Ï„                                   â”‚
â”‚                                                          â”‚
â”‚ Output: ìµœì  í™€ë“œë°±(t*) ë° ìµœëŒ€ ìˆ˜ìµ                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            PART 3-2: ì˜í™” ìœ í˜•ë³„ ë¶„ì„                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Segmentation:                                            â”‚
â”‚  - High TFS (ì´ë²¤íŠ¸í˜•)   â†’ ìµœì  t í‰ê·                    â”‚
â”‚  - High ONS (OTTí˜•)      â†’ ìµœì  t í‰ê·                    â”‚
â”‚  - Balanced              â†’ ìµœì  t í‰ê·                    â”‚
â”‚                                                          â”‚
â”‚ Output: TFS/ONS ë§¤íŠ¸ë¦­ìŠ¤ + ìµœì  í™€ë“œë°± íˆíŠ¸ë§µ            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          PART 3-3: ì‚°ì—… ìƒíƒœê³„ ì‹œë®¬ë ˆì´ì…˜                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Policy Scenarios:                                        â”‚
â”‚  1. Laissez-faire (ììœ¨)                                â”‚
â”‚  2. Uniform 90 (ì¼ê´„ ê·œì œ)                               â”‚
â”‚  3. Dynamic (ë™ì  ì°¨ë“±)                                  â”‚
â”‚                                                          â”‚
â”‚ Stakeholder Utilities:                                  â”‚
â”‚  - U_MD (ë°°ê¸‰ì‚¬)                                         â”‚
â”‚  - U_Indie (ë…ë¦½ ì œì‘ì‚¬)                                 â”‚
â”‚  - U_Local_OTT (êµ­ë‚´ OTT)                                â”‚
â”‚  - U_Consumer (ì†Œë¹„ì)                                   â”‚
â”‚                                                          â”‚
â”‚ Objective: Maximize W_Industry                          â”‚
â”‚           s.t. U_Indie â‰¥ Min_Threshold                  â”‚
â”‚                U_OTT â‰¥ Competition_Threshold            â”‚
â”‚                                                          â”‚
â”‚ Output: ìµœì  ì •ì±… + ì œì•½ ì¡°ê±´ ë§Œì¡± ì—¬ë¶€                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”‘ í•µì‹¬ ë³€ìˆ˜ ë§¤í•‘

| Model 2 ì‚°ì¶œë¬¼ | Part 3 ì‚¬ìš©ì²˜ | ì„¤ëª… |
|----------------|--------------|------|
| `Rb(t)` | ê·¹ì¥ ìˆ˜ìµ ê³„ì‚° | OTT ë¯¸ê°œì… ì‹œ ìì—° ìˆ˜ìµ ê³¡ì„  |
| `Ra(t)` | ê·¹ì¥ ìˆ˜ìµ ê³„ì‚° | í™€ë“œë°± t ì´í›„ ì ì‹ ë°˜ì˜ ê³¡ì„  |
| `TFS` | Ï„(t) ê³„ì‚°, ì˜í™” ë¶„ë¥˜ | ê·¹ì¥ ì í•©ë„ (ì´ë²¤íŠ¸ì„±) |
| `ONS` | Ï„(t) ê³„ì‚°, ì˜í™” ë¶„ë¥˜ | OTT ì í•©ë„ (ëª°ì…ë„) |
| `cannibalization_coef` | Ra(t) ìƒì„± | ì ì‹ ê³„ìˆ˜ C |
| `gamma` | Ra(t) ìƒì„±, ì†Œë¹„ì íš¨ìš© | ì—°ë„ë³„ ì†Œë¹„ì ì„ í˜¸ë„ (0~1 ì •ê·œí™”) |

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. Rolling Prediction ëˆ„ì  ì˜¤ì°¨

- **ë¬¸ì œ**: 180ì¼ ì˜ˆì¸¡ ì‹œ ì˜¤ì°¨ ëˆ„ì  ê°€ëŠ¥
- **í•´ê²°**:
  - ì´ˆê¸° 7ì¼ì€ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©
  - 14ì¼ë§ˆë‹¤ ì‹¤ì¸¡ ë°ì´í„°ë¡œ ì¬ë³´ì • (ê°€ëŠ¥ ì‹œ)
  - ì‹ ë¢°êµ¬ê°„ í‘œì‹œ (Â±1Ïƒ)

### 2. Gamma ê³„ì‚° ë° ì ìš© ë°©ë²• (ì—…ë°ì´íŠ¸ë¨)

- **ê³„ì‚° ë°©ë²•**:
  1. Log ë³€í™˜: `Î³_log = Log(OTTì´ìš©ë¥  / ê·¹ì¥ë°©ë¬¸íšŸìˆ˜)`
  2. Min-Max Scaling: `Î³_norm = (Î³_log - min) / (max - min)`
  3. ê²°ê³¼: 0~1 ë²”ìœ„ (0 = ê·¹ì¥ ì„ í˜¸, 1 = OTT ì„ í˜¸)
  
- **ì ì‹ ê³„ìˆ˜ ì ìš©**:
  - `gamma_multiplier = 0.5 + gamma`
  - gamma=0 â†’ 0.5 (ì ì‹ 50% ê°ì†Œ)
  - gamma=0.5 â†’ 1.0 (ì¤‘ë¦½)
  - gamma=1 â†’ 1.5 (ì ì‹ 50% ì¦ê°€)

- **í˜„ì¬**: ì—°ë„ë³„ ì „ì²´ ì—°ë ¹ëŒ€ í‰ê·  gamma ì‚¬ìš©
- **í•œê³„**: ì˜í™”ë³„ íƒ€ê²Ÿ ì—°ë ¹ëŒ€ ì°¨ì´ ë¯¸ë°˜ì˜
- **í–¥í›„**: ê´€ëŒë“±ê¸‰, ì¥ë¥´ë³„ ì£¼ ê´€ê°ì¸µ ë°ì´í„° í™•ë³´ í•„ìš”

- **âš ï¸ ì¤‘ìš” ë³€ê²½ì‚¬í•­ (2024-11-19)**:
  - ê¸°ì¡´: `exp(gamma)`ë¡œ ë³€í™˜ â†’ ê³¼ì†Œí‰ê°€ ë¬¸ì œ
  - ê°œì„ : Min-Max Scalingìœ¼ë¡œ 0~1 ì •ê·œí™” â†’ ì •í™•í•œ ë°˜ì˜

### 3. Base Rate íŒŒë¼ë¯¸í„°

- **ê¸°ë³¸ê°’**: 0.3 (30%)
- **ë¯¼ê°ë„ ë¶„ì„ í•„ìš”**:
  - Conservative: 0.15
  - Neutral: 0.30
  - Aggressive: 0.50

### 4. Model 3 (Ï„ ì¶”ì •) ì—°ë™

- Model 2ëŠ” Rb/Raë§Œ ì œê³µ
- **ë””ì§€í„¸ ê¶Œë¦¬ë£Œ(Ï„)**ëŠ” ë³„ë„ Model 3 í•„ìš”:
  ```
  Ï„(t, TFS, ONS) = (Total Cost Ã— R%) Ã— (1 + ONS) Ã— 1/(1 + d(TFS)Â·t)
  ```

---

## ğŸ“‚ íŒŒì¼ êµ¬ì¡°

```
model_2/
â”œâ”€â”€ main.ipynb                      # ëª¨ë¸ êµ¬ì¶• ë…¸íŠ¸ë¶
â”œâ”€â”€ model_2A_Rb_LSTM.h5            # í•™ìŠµëœ LSTM ëª¨ë¸
â”œâ”€â”€ model_Rb_best.h5               # Best checkpoint
â”œâ”€â”€ scaler_X.pkl                    # ì…ë ¥ ìŠ¤ì¼€ì¼ëŸ¬
â”œâ”€â”€ scaler_y.pkl                    # íƒ€ê²Ÿ ìŠ¤ì¼€ì¼ëŸ¬
â”œâ”€â”€ movie_meta_with_cannib.csv     # ì˜í™” ë©”íƒ€ + ì ì‹ ê³„ìˆ˜
â”œâ”€â”€ MODEL_2_BUILD_PLAN.md          # êµ¬ì¶• ê³„íšì„œ
â””â”€â”€ model2_usage.md                # ë³¸ ë¬¸ì„œ (ì‚¬ìš© ê°€ì´ë“œ)
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Quick Start)

```python
# 1. í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ import
import numpy as np
import pandas as pd
from tensorflow.keras.models import load_model
import pickle

# 2. Model 2 ì‚°ì¶œë¬¼ ë¡œë“œ
model_Rb = load_model('model_2/model_2A_Rb_LSTM.h5')
scaler_X = pickle.load(open('model_2/scaler_X.pkl', 'rb'))
scaler_y = pickle.load(open('model_2/scaler_y.pkl', 'rb'))
movie_meta = pd.read_csv('model_2/movie_meta_with_cannib.csv', encoding='utf-8')

# 3. main.ipynbì˜ í•¨ìˆ˜ import (ê°™ì€ í™˜ê²½ì—ì„œ ì‹¤í–‰)
# %run model_2/main.ipynb  # Jupyter í™˜ê²½
# ë˜ëŠ” í•¨ìˆ˜ ë³µì‚¬

# 4. ìƒ˜í”Œ ì˜ˆì¸¡ ì‹¤í–‰
movie_id = movie_meta.iloc[0]['movie_cd']
days, Rb, Ra, info = predict_revenue_curves(movie_id, holdback_days=30, horizon=180)

print(f"ì˜í™”: {info['movie_nm']}")
print(f"Rb ì´í•©: {np.sum(Rb)/1e8:.1f}ì–µ")
print(f"Ra ì´í•©: {np.sum(Ra)/1e8:.1f}ì–µ")
print(f"ì ì‹ë¥ : {(1 - np.sum(Ra)/np.sum(Rb))*100:.1f}%")
```

---

## ğŸ“ ë¬¸ì˜ ë° ì´ìŠˆ

- Model 2 êµ¬ì¶• ê´€ë ¨: `main.ipynb` ì°¸ì¡°
- Part 3 ì‹œë®¬ë ˆì´ì…˜ ì„¤ê³„: `readme.md` ë˜ëŠ” `readme_addedgammafuction.md` ì°¸ì¡°
- ë°ì´í„° ì†ŒìŠ¤: `MODEL_2_BUILD_PLAN.md` ì°¸ì¡°

---

**Last Updated**: 2024-11-19  
**Version**: 1.0

